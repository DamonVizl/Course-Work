{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.1P-Damon Vizl-s223545885- s223545885@deakin.edu.au\n",
    "## Question 1\n",
    "The Data that I have used for this task is the University of Wisconsin Hospital Breast Cancer data. The problem that is to be solved in this task is to classify whether a person has a benign or malignant breast cancer. \n",
    "The data set is 699 rows long and has 9 distinct features and was recorded by the University of Wisconsin Hospital.  \n",
    "These features are; Clump Thickness, Uniformity of Cell Size, Uniformity of Cell Shape, Marginal Adhesion, Single Epithelial Cell Size, Bare Nuclei, Bland Chromatin, Normal Nucleoli, and Mitoses.  \n",
    "The class column is the target of the model with a 2 representing a benign growth and a 4 representing a malignant cancer. \n",
    "\n",
    "The Machine learning model will need to take new data points with these 9 features and classify whether that patient has a benign or malignant growth. Due to the importance of the accuracy of this data it is critical that the model is highly accurate and has a very low return of false negatives. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "### Data Ingestion\n",
    "\n",
    "The code block below opens the csv file and using chardet.detect determines the encoding and decodes the csv file. \n",
    "We then add a columns names row and drop the \"ID Number\" column as it is not a feature of this data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chardet \n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pickle   \n",
    "import zipfile\n",
    "\n",
    "#location of the diagnosis data\n",
    "dataRefLoc = r\"./breast-cancer-wisconsin.data\"\n",
    "\n",
    "#determine the encoding of the data so the data can be generic data. \n",
    "def GetDataEncoding(url):\n",
    "    with open(url, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    result = chardet.detect(data)\n",
    "\n",
    "    return result[\"encoding\"]\n",
    "\n",
    "\n",
    "\n",
    "#read the data into the data frame. As there is no header I have used the argument header=None to stop the first row becoming the header\n",
    "dataDF = pd.read_csv(dataRefLoc, delimiter= \"\\,\", encoding = GetDataEncoding(dataRefLoc), header = None, engine= \"python\")\n",
    "#this line adds a new header row, data taken from the meta data of the data. \n",
    "dataDF.columns= [\"ID Number\", \"Clump Thickness\", \"Uniformity of Cell Size\", \"Uniformity of Cell Shape\", \"Marginal Adhesion\", \"Single Epithelial Cell Size\", \"Bare Nuclei\", \"Bland Chromatin\", \"Normal Nucleoli\", \"Mitoses\", \"Class\"]\n",
    "#as the ID number has no bearing on the class (benign or malignant) we will drop the first row.\n",
    "dataDF.drop(\"ID Number\", axis = 1, inplace= True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning \n",
    "\n",
    "As the data is raw without headers I have taken the attribute information from the data set website and added that as a header row for the data. I am also changing the commas to periods in the first column to better align with Australian data representation and processing of the data. \n",
    "\n",
    "I run dataDF.infer_objects() to convert the objects to ints where possible. Then I run dtypes to confirm which columns need processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clump Thickness                 int64\n",
       "Uniformity of Cell Size         int64\n",
       "Uniformity of Cell Shape        int64\n",
       "Marginal Adhesion               int64\n",
       "Single Epithelial Cell Size     int64\n",
       "Bare Nuclei                    object\n",
       "Bland Chromatin                 int64\n",
       "Normal Nucleoli                 int64\n",
       "Mitoses                         int64\n",
       "Class                           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#infer better data types\n",
    "dataDF = dataDF.infer_objects()\n",
    "dataDF.dtypes\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from infer_objects that all the data has been classified correctly except for the 'bare nuclei' column. I will force this column to numeric and then forward fill the NaN values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clump Thickness                int64\n",
       "Uniformity of Cell Size        int64\n",
       "Uniformity of Cell Shape       int64\n",
       "Marginal Adhesion              int64\n",
       "Single Epithelial Cell Size    int64\n",
       "Bare Nuclei                     int8\n",
       "Bland Chromatin                int64\n",
       "Normal Nucleoli                int64\n",
       "Mitoses                        int64\n",
       "Class                          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#takes the coloumn in question and forces it to be numeric.\n",
    "dataDF[\"Bare Nuclei\"] = pd.to_numeric(dataDF[\"Bare Nuclei\"], errors=\"coerce\")\n",
    "#finds any NaN and replaces them with the row above using forward fill\n",
    "dataDF[\"Bare Nuclei\"] = dataDF[\"Bare Nuclei\"].fillna(method=\"ffill\")\n",
    "#down cast to an int to reduce memory and increase processing.\n",
    "dataDF[\"Bare Nuclei\"] = pd.to_numeric(dataDF[\"Bare Nuclei\"], downcast= \"integer\")\n",
    "dataDF.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block below loads a LabelEncoder into the labelEncoder variable and then drops the \"class\" column (as this is our target) before encoding the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoder = preprocessing.LabelEncoder()\n",
    "targetName = \"Class\"\n",
    "X = dataDF.drop(targetName, axis = 1).values\n",
    "y = dataDF[targetName].values\n",
    "\n",
    "for ij in range(0,X.shape[1]):\n",
    "    X[:,ij] = labelEncoder.fit_transform(X[:,ij])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training - Decision Tree\n",
    "\n",
    "Now that we have ingested and cleaned the data it is time to train the data. I will first do a decision tree model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size = 0.2 #the percentage of train to test data. 80 percent of the data will be allocated to train and 20 to test\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,y,test_size=validation_size)\n",
    "DT = DecisionTreeClassifier(criterion=\"entropy\", max_features=len(X[0]), max_depth=10)\n",
    "\n",
    "DT = DT.fit(X_train, Y_train)\n",
    "y_prediction_DT = DT.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training - Random Forrest\n",
    "Above we have trained the data through an Entropy Decision Tree. Below is a random forrest classifier test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC = RandomForestClassifier(n_estimators=100)\n",
    "RFC = RFC.fit(X_train, Y_train)\n",
    "y_prediction_RFC = RFC.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the Model\n",
    "\n",
    "As this is a classification problem we can use the sklearn metrics within the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.97      0.94      0.95        89\n",
      "           4       0.91      0.94      0.92        51\n",
      "\n",
      "    accuracy                           0.94       140\n",
      "   macro avg       0.94      0.94      0.94       140\n",
      "weighted avg       0.94      0.94      0.94       140\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.98      0.98      0.98        89\n",
      "           4       0.96      0.96      0.96        51\n",
      "\n",
      "    accuracy                           0.97       140\n",
      "   macro avg       0.97      0.97      0.97       140\n",
      "weighted avg       0.97      0.97      0.97       140\n",
      "\n",
      "Decision Tree True Negatives: 84, False Negatives: 5, False Positives: 3, True Positives: 48\n",
      "Random Forrest True Negatives: 87, False Negatives: 2, False Positives: 2, True Positives: 49\n"
     ]
    }
   ],
   "source": [
    "#Below are two classification reports from the Sklearn package. This provides precision, recall, f1-score and accuracy. \n",
    "reportDT = classification_report(Y_test, y_prediction_DT)\n",
    "reportRFC = classification_report(Y_test, y_prediction_RFC)\n",
    "print(reportDT)\n",
    "print(reportRFC)\n",
    "\n",
    "#the confusion matrix provides us number of true positives, false positives, true negatives and false negatives.\n",
    "confusionMatrixDT = confusion_matrix(Y_test, y_prediction_DT)\n",
    "confusionMatrixRFC = confusion_matrix(Y_test, y_prediction_RFC)\n",
    "print(f\"Decision Tree True Negatives: {confusionMatrixDT[0,0]}, False Negatives: {confusionMatrixDT[0,1]}, False Positives: {confusionMatrixDT[1,0]}, True Positives: {confusionMatrixDT[1,1]}\")\n",
    "print(f\"Random Forrest True Negatives: {confusionMatrixRFC[0,0]}, False Negatives: {confusionMatrixRFC[0,1]}, False Positives: {confusionMatrixRFC[1,0]}, True Positives: {confusionMatrixRFC[1,1]}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "**Accuracy** Accuracy is a measure of total correct predictions divided by the total number of predictions. From our analysis on the accuracy we can see that the Decision tree had an accuracy of approximately 96% while the Random Forrest had an accuracy of 99%.  \n",
    "**Precision** Precision is calculated using the number of true positives divided by the total number of positive predictions. We can see that the Decision Tree was more precise in reporting true negatives and less precise in reporting true positives. The reverse is true for the Random Forrest. In the medical field it is more important to register true positives, this would provide weight in using this model as we are analysing breast cancer data. The DT had a weighted average precision of 96% and the RFC had a weighted average precision of 99%.  \n",
    "**Recall** Recall is a measure of how well a model can identify positive samples. It is calculated by dividing the number of true positives by the total number of positives. For the DT the recall had a weighted average of 96% and the RFC had a weighted recall of 99%.  \n",
    "**F1 Score** The F1 score is an overall indicator of the models performance. IT takes into account the precision and recall. The DT had a weighted average of 96% and the RFC has a weighted average of 99%. \n",
    "We can see that with an accuracy of 99% the RFC model is performing exceedingly well. When combined with radiographers and oncologists this would be an extremly useful tool in diagnosing cancer.  \n",
    "\n",
    "## Question 4\n",
    "We can see from the above metrics that the model that performs the best (most accurate) between the two is the Random Forrest model. This is due to the way that the model takes random samples and runs 100 tests to develop the model. As it is built on multiple Decision Trees it removes the accuracy issues presented by a single Decision Tree model. As our data set is relatively small the Random Forrest also performs better. Given the metrics mentioned above the RFC model outperforms the DT model in all regards. We know that the DT model is prone to variance in test sets and new data due to it's dependancy on it's training data. The RFC model rectifies this by selecting random allotments of data and random selection of features. This randomness uncouples the model from the training data more effectively.  \n",
    "Due to the RFC model running training on random features it removes issues with regard to the feature selection and any one feature that may be skewing the data is less relied upon.  \n",
    "Importantly the number of false negatives in the RFC model is 0. This is potentially the most important metric as a false negative could see a patient not undergo treatment or further investigation. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export the model \n",
    "f = open(\"RFC_Model.pkl\", \"wb\")\n",
    "pickle.dump(RFC,f)\n",
    "f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target Grade: HD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "This breast cancer databases was obtained from the University of Wisconsin Hospitals, Madison from Dr. William H. Wolberg.\n",
    "O. L. Mangasarian and W. H. Wolberg: \"Cancer diagnosis via linear programming\", SIAM News, Volume 23, Number 5, September 1990, pp 1 & 18.\n",
    "\n",
    "@article{scikit-learn,\n",
    " title={Scikit-learn: Machine Learning in {P}ython},\n",
    " author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.\n",
    "         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.\n",
    "         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and\n",
    "         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},\n",
    " journal={Journal of Machine Learning Research},\n",
    " volume={12},\n",
    " pages={2825--2830},\n",
    " year={2011}\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
